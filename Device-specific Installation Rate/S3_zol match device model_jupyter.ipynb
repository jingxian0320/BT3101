{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Script Index: S3\n",
    "## Author: Liu Yue\n",
    "## Date: 03/10/2016\n",
    "## Python Version: Anaconda 4.2.0, python 3.5\n",
    "\n",
    "\"\"\" \n",
    "    This script matches the names of device models on ZOL and on TalkingData\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Methods for name tokenisation\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "def rename(s, brand_name):\n",
    "    \"\"\" Method for name tokenizasion, with steps explained \"\"\"\n",
    "    # Step 1: change lower to UPPER\n",
    "    s = s.upper()\n",
    "    # Step 2: remove brand name \n",
    "    s = s.replace(brand_name, '')\n",
    "    # Step 3: synonyms\n",
    "    s = s.replace('+',' PLUS')\n",
    "    s.replace('TAB','') \n",
    "    s = s.replace('III', '3')\n",
    "    s = s.replace('II', '2')\n",
    "    s = s.replace('MI', '')\n",
    "    s = s.replace('.0', '')\n",
    "    # Step 4: replace meaningless punctuations\n",
    "    random_char = \"_.-?!@/#$)(（）\"\n",
    "    for char in random_char:\n",
    "        s = s.replace(char,' ')    \n",
    "    # Step 5 seperate into tokens (Chinese, [0-9], [a-zA-Z], others) and remove empty spaces\n",
    "    lst = str2List(s)\n",
    "    token_set = set([token for token in lst if token != ' '])\n",
    "    return(token_set)\n",
    "\n",
    "def char_type(uchar):\n",
    "    \"\"\"Method to get the type of character: Chinese, 0-9, a-zA-Z, other\"\"\"\n",
    "    if uchar >= u'\\u4e00' and uchar<=u'\\u9fa5':\n",
    "        return('is_chinese') \n",
    "    if uchar >= u'\\u0030' and uchar<=u'\\u0039':\n",
    "        return('is_number')\n",
    "    if (uchar >= u'\\u0041' and uchar<=u'\\u005a') or (uchar >= u'\\u0061' and uchar<=u'\\u007a'):\n",
    "        return ('is_alphabet')\n",
    "    else:\n",
    "        return ('is_other')\n",
    "\n",
    "def str2List (ustring):\n",
    "    \"\"\"Method for somewhat '1-gram' tokennization\n",
    "    string to tokens by character type, e.g. '倾城L3C' -> ['倾城', 'L', '3', 'C']\"\"\"\n",
    "    retList=[]\n",
    "    token=''\n",
    "    old_char_type = 'is_other'\n",
    "    for i in range(0,len(ustring)):\n",
    "        uchar = ustring[i]\n",
    "        new_char_type = char_type(uchar)\n",
    "        if i == 0 or new_char_type == old_char_type:\n",
    "            token = token + uchar\n",
    "            old_char_type = new_char_type\n",
    "        else:\n",
    "            retList.append(token)\n",
    "            token = uchar\n",
    "            old_char_type = new_char_type\n",
    "    retList.append(token)\n",
    "    return(retList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data loaded ['三星', '三星GALAXY S7 Edge（G9350/全网通）', '/cell_phone/index1100338.shtml']\n",
      "Relevant fields: zol_name, zol_link, zol_token\n",
      "Sample data:\n",
      " [['三星', '三星GALAXY Note 7（N9300/全网通）', '/cell_phone/index1116686.shtml', {'GALAXY', '全网通', '9300', '7', 'N', 'NOTE'}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loading: phone data scraped from Script S2\"\"\"\n",
    "## Load zol_phone_model: [[phone_brand, zol_name, zol_link], ...]\n",
    "with open('S2_zol phone model link.csv', newline='',encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    zol_phone_model = list(file)\n",
    "zol_phone_model[0][0] = zol_phone_model[0][0].replace(u'\\ufeff', '') # Remove Byte Order Mark character at start of file\n",
    "print('Sample data loaded', zol_phone_model[1])\n",
    "\n",
    "## Tokenize name in zol_phone_model: [[phone_brand, zol_name, zol_link, zol_token], ...]\n",
    "for line in zol_phone_model:\n",
    "    line.append(rename(line[1], line[0]))\n",
    "print('Relevant fields: zol_name, zol_link, zol_token')\n",
    "print('Sample data:\\n', zol_phone_model[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data loaded ['酷比魔方IWORK11手写版', '/tablepc/index1110165.shtml']\n",
      "Relevant fields: zol_name, zol_link, zol_token\n",
      "Sample data:\n",
      " [['华为揽阅 M2 10.0（64GB/WiFi版）', '/tablepc/index1137541.shtml', {'版', 'WIFI', '华为揽阅', 'GB', '2', '10', '64', 'M'}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loading: tablet data scraped from Script S2\"\"\"\n",
    "import csv\n",
    "## Load zol_tablet_model: [[zol_name, zol_link], ...]\n",
    "with open('S2_zol tablet model link.csv', newline='',encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    zol_tablet_model = list(file)\n",
    "zol_tablet_model[0][0] = zol_tablet_model[0][0].replace(u'\\ufeff', '') # Remove Byte Order Mark character at start of file\n",
    "print('Sample data loaded', zol_tablet_model[1])\n",
    "\n",
    "## Tokenize name in zol_tablet_model: [[zol_name, zol_link, zol_token], ...]\n",
    "for line in zol_tablet_model:\n",
    "    line.append(rename(line[0], \"\"))\n",
    "## Show sample data\n",
    "print('Relevant fields: zol_name, zol_link, zol_token')\n",
    "print('Sample data:\\n', zol_tablet_model[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data loaded: ['1;\"爱派尔\";\"iPh-800\";\"3\"']\n",
      "Relevant fields: device_model_index, phone_brand, tk_name, count_device_id, tk_token\n",
      "Sample data  [['1', '爱派尔', 'iPh-800', '3', {'800', 'IPH'}]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loading: data pre-processed by MySQL and saved as .csv \n",
    "    Possible but complex to load directly as MySQL charset not complient to universal charset\n",
    "    See detailed loading method in Week 7 journal\"\"\"\n",
    "\n",
    "## Load tk data: [[device_model_index, phone_brand, tk_name, count_device_id], ...]\n",
    "import csv\n",
    "import re\n",
    "with open('S0_device_model_count.csv', newline='',encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    tk_device = list(file)\n",
    "tk_device = sum(tk_device, [])\n",
    "print('Sample data loaded:', tk_device[:1] )\n",
    "\n",
    "def format_sql_line (s):\n",
    "    lst = re.split('\"|;', s.replace('\"',''))\n",
    "    return lst\n",
    "tk_device_models = [format_sql_line(line) for line in tk_device]\n",
    "\n",
    "## Tokenize name for tk_device_models: [[device_model_index, phone_brand, tk_name, count_device_id, tk_token], ...]\n",
    "## Add the re-name to each tk_device_model \n",
    "for line in tk_device_models:\n",
    "    line.append(rename(line[2], line[1]))\n",
    "\n",
    "print('Relevant fields: device_model_index, phone_brand, tk_name, count_device_id, tk_token')\n",
    "print('Sample data ', tk_device_models[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Match zol phone with tk device models\n",
    "    Under each brand:\n",
    "    Match tk_name with zol_names, using subset method (tk <= zol) \"\"\"\n",
    "\n",
    "## Brand_found: tk brands with data on zol \n",
    "brands = []\n",
    "for line in zol_phone_model: brands.append(line[0])\n",
    "brands_found = list(set(brands))\n",
    "\n",
    "## Tk device models, with brand data on zol\n",
    "tk_dm_found = [line for line in tk_device_models if line[1] in brands_found]\n",
    "\n",
    "\n",
    "def tk_filter(seq, brand_name):\n",
    "    \"\"\" Method to filter tk phone names by brand\"\"\"\n",
    "    return ([line for line in seq if line[1]==brand_name])\n",
    "\n",
    "def zol_filter(seq, brand_name):\n",
    "    \"\"\" Method to filter zol phone names by brand\"\"\"\n",
    "    return ([line for line in seq if line[0]==brand_name])\n",
    "\n",
    "def order_match(match_rough):\n",
    "    \"\"\" Method to order list for easy filtering \"\"\"\n",
    "    match_1_index = set(line[0] for line in match_rough if line[7]>0) - set(line[0] for line in match_rough if line[7]>1) \n",
    "    match_1_ordered = sorted([line for line in match_rough if line[0] in match_1_index], key=lambda line:int(line[0]))\n",
    "    ## More than one matches\n",
    "    match_more_index = set(line[0] for line in match_rough if line[7]>1)\n",
    "    match_more =  [line for line in match_rough if line[0] in match_more_index]\n",
    "    ## 1. Ordered by increasing token numbers in zol_name (most similar first)\n",
    "    match_more_ordered = sorted(match_more, key=lambda line:line[6])\n",
    "    ## 2. Ordered by increasing tk_index\n",
    "    match_more_ordered = sorted(match_more_ordered, key=lambda line:int(line[0]))\n",
    "    ## No match\n",
    "    match_0_ordered = sorted([line for line in match_rough if line[7]==0], key=lambda line:int(line[0]))\n",
    "    match_ordered = match_1_ordered + match_more_ordered + match_0_ordered\n",
    "    return(match_ordered)\n",
    "\n",
    "\n",
    "match_rough = []\n",
    "for brand_name in brands_found:\n",
    "    \"\"\" Get a rough match for names, using subset method (tk <= zol) \"\"\"\n",
    "    tk_dm = tk_filter(tk_dm_found, brand_name)\n",
    "    zol_dm = zol_filter(zol_phone_model, brand_name)\n",
    "\n",
    "    ## Match names, record number of matches\n",
    "    for tk in tk_dm:\n",
    "        tk_index = tk[0]\n",
    "        tk_phone_brand = tk[1]\n",
    "        tk_device_model = tk[2]\n",
    "        tk_count = tk[3]\n",
    "        tk_token = tk[4]\n",
    "        count = 0\n",
    "        for zol in zol_dm:\n",
    "            if tk_token.issubset(zol[3]):\n",
    "                count += 1\n",
    "                match = [tk_index, tk_phone_brand, tk_count, tk_device_model, zol[1], zol[2], len(zol[3]), count]\n",
    "                match_rough.append(match)\n",
    "        if count == 0:\n",
    "            match = [tk_index, tk_phone_brand, tk_count, tk_device_model, '', '', len(zol[3]), count]\n",
    "            match_rough.append(match)           \n",
    "            \n",
    "for tk in tk_dm_not_found:\n",
    "    tk_index = tk[0]\n",
    "    tk_phone_brand = tk[1]\n",
    "    tk_device_model = tk[2]\n",
    "    tk_count = tk[3]\n",
    "    tk_token = tk[4]\n",
    "    for zol in zol_tablet_model:       \n",
    "        if tk_token.issubset(zol[2]):\n",
    "            match = [tk_index, tk_phone_brand, tk_count, tk_device_model, zol[0], zol[1]]\n",
    "            match_rough.append(match)\n",
    "\n",
    "## Write the data to CSV files\n",
    "with open('S3_zol phone match device model_rough.csv','w',newline='',encoding='utf-8-sig') as f:\n",
    "    a = csv.writer(f)\n",
    "    a.writerows(match_rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get back the list\n",
    "\n",
    "## Load found device models: [[device_model_index, phone_brand, count_device_id, tk_name, zol_name, zol_link], ...]\n",
    "with open('S3_zol phone match device model_rough.csv', newline='',encoding='utf-8-sig') as f:\n",
    "    file = csv.reader(f)\n",
    "    lst = list(file)\n",
    "lst == match_rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precentage of device_model not found: 0.1610517666392769\n",
      "Number of device_model not found: 196\n",
      "Precentage of device_id not found: 0.08068488932982108\n",
      "Number of device_id not found: 4717\n",
      "\n",
      "Top device_model not found: [['620', 'vivo', 'X5Pro', '386', {'X', '5', 'PRO'}], ['624', 'vivo', 'X6 D', '258', {'X', '6', 'D'}], ['612', 'vivo', 'X3L', '236', {'X', '3', 'L'}], ['617', 'vivo', 'X5M', '224', {'X', '5', 'M'}], ['619', 'vivo', 'X5Max+', '224', {'X', 'PLUS', '5', 'MAX'}], ['621', 'vivo', 'X5SL', '210', {'X', 'SL', '5'}], ['651', 'vivo', 'Y27', '177', {'27', 'Y'}], ['650', 'vivo', 'Y23L', '170', {'23', 'L', 'Y'}], ['630', 'vivo', 'Xplay3S', '151', {'S', '3', 'XPLAY'}], ['616', 'vivo', 'X5L', '142', {'X', '5', 'L'}]]\n"
     ]
    }
   ],
   "source": [
    "lst=[l for l in match_rough if l[0]!='']\n",
    "## Set of device_model_index already found\n",
    "indexes_found = set(l[0] for l in lst)\n",
    "\n",
    "## Top device_model not found\n",
    "tk_dm_not_found = [x for x in tk_device_models if x[0] not in indexes_found]\n",
    "dm_not_found_top = sorted(tk_dm_not_found, key=lambda line:int(line[3]), reverse=True)\n",
    "\n",
    "print('Precentage of device_model not found:', 1-len(set(indexes_found))/1217)\n",
    "print('Number of device_model not found:', 1217 - len(set(indexes_found)))\n",
    "print('Precentage of device_id not found:', sum([int(x[3]) for x in tk_dm_not_found])/58462)\n",
    "print('Number of device_id not found:', sum([int(x[3]) for x in tk_dm_not_found]))\n",
    "print('\\nTop device_model not found:', dm_not_found_top[:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
