{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Script Index: S2\n",
    "## Author: Liu Yue\n",
    "## Date: 30/09/2016\n",
    "## Python Version: Anaconda 4.2.0, python 3.5\n",
    "\n",
    "\"\"\" \n",
    "    Data Scraping:\n",
    "    This script gets the all names of and links to device models\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import csv\n",
    "import re\n",
    "\n",
    "## Function: Form BeautifulSoup object with exception handling \n",
    "def bsObjFormation(url):\n",
    "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    headers={'User-Agent':user_agent,}\n",
    "    try:\n",
    "        request=urllib.request.Request(url,None,headers) #The assembled request # may have TimeoutError\n",
    "    except TimeoutError:\n",
    "        pass\n",
    "    try:\n",
    "        htmlfile=urllib.request.urlopen(request)\n",
    "        bsObj = BeautifulSoup(htmlfile.read(), \"html.parser\", )\n",
    "        return bsObj\n",
    "    except urllib.error.URLError:\n",
    "        return False;\n",
    "\n",
    "## Read tk_brands_found: tk_brand_name, brand_name_displayed, zol_link\n",
    "with open('S1_zol phone brand link.csv', newline='',encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    lst = list(file)\n",
    "lst[0][0] = lst[0][0].replace(u'\\ufeff', '') # Remove Byte Order Mark character at start of file\n",
    "brands_found = lst\n",
    "\n",
    "## Containers for recording\n",
    "zol_phones = []\n",
    "error_url = []\n",
    "error_zol_phones = []\n",
    "\n",
    "## Set url construction tool\n",
    "prefix = \"http://detail.zol.com.cn/cell_phone_index/subcate57_\"\n",
    "mid = \"_list_1_0_1_1_0_\"\n",
    "suffix = \".html\"\n",
    "\n",
    "\n",
    "## Initial trial: all names and links of zol device models, for all tk_brands on zol\n",
    "## If error occurs, pass and record the breaking point\n",
    "for brand in range(0,len(brands_found)):\n",
    "    tk_brand_name = brands_found[brand][0]\n",
    "    zol_brand_index = brands_found[brand][1].split(\"_\")[3]\n",
    "    page_index = 1\n",
    "    \n",
    "    while page_index > 0:\n",
    "        phone_page_url = prefix + zol_brand_index + mid + str(page_index) + suffix    \n",
    "        try:\n",
    "            bsObj = bsObjFormation(phone_page_url)\n",
    "        except Exception: #except urllib.error.URLError as err:\n",
    "            bsObj = False\n",
    "        if bsObj != False :\n",
    "            lst = bsObj.findAll(\"div\",class_=\"pro-intro\")        \n",
    "            for i in range(0,len(lst)):\n",
    "                line = lst[i].h3.a\n",
    "                phone_name = line.text\n",
    "                link = line[\"href\"]\n",
    "                zol_phones.append([tk_brand_name,phone_name,link])\n",
    "            if bsObj.findAll(\"a\",class_=\"small-page-next\"):\n",
    "                page_index = page_index + 1\n",
    "                # page_index = int(bsObj.findAll(\"a\",class_=\"small-page-next\")[0][\"href\"].split(\"_\")[10][:-5]) + 1\n",
    "            else:\n",
    "                page_index = -1\n",
    "        else:\n",
    "            error_url.append([\"error\",tk_brand_name,phone_page_url])\n",
    "            page_index = -1\n",
    "\n",
    "## Handel the breaking points: all names and links of zol device models, for all tk_brands on zol\n",
    "for i in range(0,len(error_url)):\n",
    "    seed_page = error_url[i]\n",
    "    tk_brand_name = seed_page[1]\n",
    "    phone_page_url = seed_page[2]\n",
    "    ## Instead of forcing through: page_index = int(phone_page_url.split(\"_\")[10][:-5])\n",
    "    ## Use regular expression\n",
    "    page_index = int(re.search('([\\w.-]+)_([\\w.-]+).html',phone_page_url).group(2))\n",
    "    zol_brand_index = re.search('_([\\w.-]+)_list',phone_page_url).group(1)\n",
    "    while page_index > 0:\n",
    "        phone_page_url = prefix + zol_brand_index + mid + str(page_index) + suffix    \n",
    "        try:\n",
    "            bsObj = bsObjFormation(phone_page_url)\n",
    "        except Exception: #except urllib.error.URLError as err:\n",
    "            bsObj = False\n",
    "        if bsObj != False :\n",
    "            lst = bsObj.findAll(\"div\",class_=\"pro-intro\")        \n",
    "            for i in range(0,len(lst)):\n",
    "                line = lst[i].h3.a\n",
    "                phone_name = line.text\n",
    "                link = line[\"href\"]\n",
    "                error_zol_phones.append([tk_brand_name,phone_name,link])\n",
    "            if bsObj.findAll(\"a\",class_=\"small-page-next\"):\n",
    "                page_index = page_index + 1\n",
    "                # page_index = int(bsObj.findAll(\"a\",class_=\"small-page-next\")[0][\"href\"].split(\"_\")[10][:-5]) + 1\n",
    "            else:\n",
    "                page_index = -1\n",
    "        else:\n",
    "            error_url.append([\"error\",tk_brand_name,phone_page_url])\n",
    "            page_index = -1\n",
    "\n",
    "# Combine the results \n",
    "zol_phones_final = zol_phones + error_zol_phones\n",
    "\n",
    "## Write the data to CSV files\n",
    "with open('S2_zol phone model link.csv','w',newline='',encoding='utf-8-sig') as f:\n",
    "    a = csv.writer(f)\n",
    "    a.writerows(zol_phones_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## How to get back the list\n",
    "import csv\n",
    "## Read zol_phone_model: tk_brand_name,zol_phone_name,zol_link\n",
    "with open('S2_zol phone model link.csv', newline='',encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    lst = list(file)\n",
    "\n",
    "lst[0][0] = lst[0][0].replace(u'\\ufeff', '') # Remove Byte Order Mark character at start of file\n",
    "zol_phone_model = lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Get: names and links of tablet models on zol \n",
    "\"\"\"\n",
    "\n",
    "# scrape data(name, link) for tablet\n",
    "prefix = \"http://detail.zol.com.cn/tablepc/\"\n",
    "suffix = \".html\"\n",
    "index_range = range(1,136)\n",
    "\n",
    "zol_tablets = []\n",
    "for index in index_range:\n",
    "    tablet_url = prefix + str(index) + suffix\n",
    "    if bsObj is not None:\n",
    "        bsObj = bsObjFormation(tablet_url)\n",
    "        lst = bsObj.findAll(\"div\",class_=\"pro-intro\")\n",
    "        for i in range(0,len(lst)):\n",
    "            line = lst[i].h3.a\n",
    "            tablet_name = line.text\n",
    "            link = line[\"href\"]\n",
    "            zol_tablets.append([tablet_name,link])\n",
    "        \n",
    "## Write the data to CSV files\n",
    "with open('S2_zol tablet model link.csv','w',newline='',encoding='utf-8-sig') as f:\n",
    "    a = csv.writer(f)\n",
    "    a.writerows(zol_tablets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
